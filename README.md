<div align="center">
  <img src="nanobot_logo.png" alt="nanobot" width="500">
  <h1>nanobot: Ultra-Lightweight Personal AI Assistant</h1>
  <p>
    <a href="https://pypi.org/project/nanobot-ai/"><img src="https://img.shields.io/pypi/v/nanobot-ai" alt="PyPI"></a>
    <a href="https://pepy.tech/project/nanobot-ai"><img src="https://static.pepy.tech/badge/nanobot-ai" alt="Downloads"></a>
    <img src="https://img.shields.io/badge/python-‚â•3.11-blue" alt="Python">
    <img src="https://img.shields.io/badge/license-MIT-green" alt="License">
    <a href="./COMMUNICATION.md"><img src="https://img.shields.io/badge/Feishu-Group-E9DBFC?style=flat&logo=feishu&logoColor=white" alt="Feishu"></a>
    <a href="./COMMUNICATION.md"><img src="https://img.shields.io/badge/WeChat-Group-C5EAB4?style=flat&logo=wechat&logoColor=white" alt="WeChat"></a>
    <a href="https://discord.gg/MnCvHqpUGB"><img src="https://img.shields.io/badge/Discord-Community-5865F2?style=flat&logo=discord&logoColor=white" alt="Discord"></a>
  </p>
</div>

üêà **nanobot** is an **ultra-lightweight** personal AI assistant inspired by [Clawdbot](https://github.com/openclaw/openclaw) 

‚ö°Ô∏è Delivers core agent functionality in just **~4,000** lines of code ‚Äî **99% smaller** than Clawdbot's 430k+ lines.

## üì¢ News

- **2026-02-01** üéâ nanobot launched! Welcome to try üêà nanobot!

## Key Features of nanobot:

ü™∂ **Ultra-Lightweight**: Just ~4,000 lines of code ‚Äî 99% smaller than Clawdbot - core functionality.

üî¨ **Research-Ready**: Clean, readable code that's easy to understand, modify, and extend for research.

‚ö°Ô∏è **Lightning Fast**: Minimal footprint means faster startup, lower resource usage, and quicker iterations.


### CI / Docker notes for building the Rust extension

When building the Rust Python extension inside CI or containers on newer Python versions (for example Python 3.14), set the following environment variable so PyO3 uses the stable ABI forward-compatibility:

```bash
export PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1
```

If you need to specify a particular Python executable for maturin builds, set `PYO3_PYTHON` to the interpreter path.
üíé **Easy-to-Use**: One-click to depoly and you're ready to go.

## üèóÔ∏è Architecture

<p align="center">
  <img src="nanobot_arch.png" alt="nanobot architecture" width="800">
</p>

## ‚ú® Features

<table align="center">
  <tr align="center">
    <th><p align="center">üìà 24/7 Real-Time Market Analysis</p></th>
    <th><p align="center">üöÄ Full-Stack Software Engineer</p></th>
    <th><p align="center">üìÖ Smart Daily Routine Manager</p></th>
    <th><p align="center">üìö Personal Knowledge Assistant</p></th>
  </tr>
  <tr>
    <td align="center"><p align="center"><img src="case/search.gif" width="180" height="400"></p></td>
    <td align="center"><p align="center"><img src="case/code.gif" width="180" height="400"></p></td>
    <td align="center"><p align="center"><img src="case/scedule.gif" width="180" height="400"></p></td>
    <td align="center"><p align="center"><img src="case/memory.gif" width="180" height="400"></p></td>
  </tr>
  <tr>
    <td align="center">Discovery ‚Ä¢ Insights ‚Ä¢ Trends</td>
    <td align="center">Develop ‚Ä¢ Deploy ‚Ä¢ Scale</td>
    <td align="center">Schedule ‚Ä¢ Automate ‚Ä¢ Organize</td>
    <td align="center">Learn ‚Ä¢ Memory ‚Ä¢ Reasoning</td>
  </tr>
</table>

## üì¶ Install

**Install from source** (latest features, recommended for development)

```bash
git clone https://github.com/eigmax/nanobot.git
cd nanobot
pip install -e .
```

**Install with [uv](https://github.com/astral-sh/uv)** (stable, fast)

```bash
uv tool install nanobot-ai
```

**Install from PyPI** (stable)

```bash
pip install nanobot-ai
```

## üöÄ Quick Start

> [!TIP]
> Set your API key in `~/.nanobot/config.json`.
> Get API keys: [OpenRouter](https://openrouter.ai/keys) (LLM) ¬∑ [Brave Search](https://brave.com/search/api/) (optional, for web search)
> You can also change the model to `minimax/minimax-m2` for lower cost.

**1. Initialize**

```bash
nanobot onboard
```

**2. Configure** (`~/.nanobot/config.json`)

```json
{
  "providers": {
    "openrouter": {
      "apiKey": "sk-or-v1-xxx"
    }
  },
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5"
    }
  },
  "webSearch": {
    "apiKey": "BSA-xxx"
  }
}
```


**3. Chat**

```bash
nanobot agent -m "What is 2+2?"
```

That's it! You have a working AI assistant in 2 minutes.

## üñ•Ô∏è Local Models (vLLM)

Run nanobot with your own local models using vLLM or any OpenAI-compatible server.

**1. Start your vLLM server**

```bash
vllm serve meta-llama/Llama-3.1-8B-Instruct --port 8000
```

**2. Configure** (`~/.nanobot/config.json`)

```json
{
  "providers": {
    "vllm": {
      "apiKey": "dummy",
      "apiBase": "http://localhost:8000/v1"
    }
  },
  "agents": {
    "defaults": {
      "model": "meta-llama/Llama-3.1-8B-Instruct"
    }
  }
}
```

**3. Chat**

```bash
nanobot agent -m "Hello from my local LLM!"
```

## üíæ Session Compaction

nanobot automatically compacts long conversations to keep context windows efficient. When a conversation exceeds ~90% of the model's context window, old messages are summarized into a single "compaction" entry.

**Features:**
- ‚úÖ **Automatic** ‚Äî Triggered silently when context limit approached
- ‚úÖ **Manual** ‚Äî Use `/compact` command in Telegram or CLI
- ‚úÖ **Configurable** ‚Äî Tune per-model or globally
- ‚úÖ **Tracked** ‚Äî View compaction stats in session metadata

**Usage:**

```bash
# Manual compaction via CLI
nanobot sessions compact telegram:12345 --keep-last 50

# View/configure compaction settings
nanobot config compaction --show
nanobot config compaction --keep-last 30 --trigger-ratio 0.85

# Per-model settings
nanobot config compaction-model "anthropic/claude-opus-4-5" --keep-last 40
```

**Telegram:**

```
/compact              # Use default keep-last=50
/compact 30           # Keep last 30 messages
/compact 30 --verbose # Show detailed results
```

## üß† Long-term memory

nanobot stores persistent memory under your workspace at `memory/` (by default your workspace is `~/.nanobot/workspace`). The memory system supports:

- `MEMORY.md` ‚Äî long-term notes you want the agent to remember.
- `YYYY-MM-DD.md` ‚Äî daily notes.
- `.index.json` ‚Äî a simple local semantic index (auto-generated).

How it works
- The Rust extension (or the Python fallback) exposes `MemoryStore.build_index()` and `MemoryStore.search(query, max_results, min_score)` to build a local vector index and search it.
- If `OPENAI_API_KEY` or `OPENROUTER_API_KEY` is set, nanobot will attempt to use the remote embeddings API and fall back to a deterministic local embedding when not available.

Quick enable & usage

1. Build and install the Rust extension (in development environments with Python ‚âß 3.14 you may need to set `PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1`):

```bash
source .venv/bin/activate
export PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1
export PYO3_PYTHON=/opt/homebrew/bin/python3.14
cd rust
maturin build --release -m Cargo.toml
cd ..
pip install rust/target/wheels/*.whl
pip install -e .
```

2. Optionally provide an embeddings key (recommended for better results):

```bash
export OPENAI_API_KEY="sk-..."
# or
export OPENROUTER_API_KEY="or-..."
```

3. Build index and search (Python example):

```python
from pathlib import Path
from nanobot.agent.memory import search_memory, MemoryStore
# Build index explicitly (if you've updated memory files)
store = MemoryStore(ws)
store.build_index()

# Search
results = search_memory(ws, "when did I last deploy?", max_results=5)
for r in results:
  print(r["score"], r["path"])
  print(r["snippet"][:200])
  print("---")
```

Notes
- If the `.index.json` file is missing, `search_memory()` will attempt to call `build_index()` automatically.
- The local deterministic embedding is SHA256-based and works offline but yields lower-quality semantic matches than remote embeddings.


> [!TIP]
> The `apiKey` can be any non-empty string for local servers that don't require authentication.

## üí¨ Chat Apps

Talk to your nanobot through Telegram or WhatsApp ‚Äî anytime, anywhere.

| Channel | Setup |
|---------|-------|
| **Telegram** | Easy (just a token) |
| **WhatsApp** | Medium (scan QR) |

<details>
<summary><b>Telegram</b> (Recommended)</summary>

**1. Create a bot**
- Open Telegram, search `@BotFather`
- Send `/newbot`, follow prompts
- Copy the token

**2. Configure**

```json
{
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "YOUR_BOT_TOKEN",
      "allowFrom": ["YOUR_USER_ID"]
    }
  }
}
```

> Get your user ID from `@userinfobot` on Telegram.

**3. Run**

```bash
nanobot gateway
```

</details>

<details>
<summary><b>WhatsApp</b></summary>

Requires **Node.js ‚â•18**.

**1. Link device**

```bash
nanobot channels login
# Scan QR with WhatsApp ‚Üí Settings ‚Üí Linked Devices
```

**2. Configure**

```json
{
  "channels": {
    "whatsapp": {
      "enabled": true,
      "allowFrom": ["+1234567890"]
    }
  }
}
```

**3. Run** (two terminals)

```bash
# Terminal 1
nanobot channels login

# Terminal 2
nanobot gateway
```

</details>

## ‚öôÔ∏è Configuration

Config file: `~/.nanobot/config.json`

### Providers

> [!NOTE]
> Groq provides free voice transcription via Whisper. If configured, Telegram voice messages will be automatically transcribed.

| Provider | Purpose | Get API Key |
|----------|---------|-------------|
| `openrouter` | LLM (recommended, access to all models) | [openrouter.ai](https://openrouter.ai) |
| `anthropic` | LLM (Claude direct) | [console.anthropic.com](https://console.anthropic.com) |
| `openai` | LLM (GPT direct) | [platform.openai.com](https://platform.openai.com) |
| `groq` | LLM + **Voice transcription** (Whisper) | [console.groq.com](https://console.groq.com) |
| `gemini` | LLM (Gemini direct) | [aistudio.google.com](https://aistudio.google.com) |


<details>
<summary><b>Full config example</b></summary>

```json
{
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5"
    }
  },
  "providers": {
    "openrouter": {
      "apiKey": "sk-or-v1-xxx"
    },
    "groq": {
      "apiKey": "gsk_xxx"
    }
  },
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "123456:ABC...",
      "allowFrom": ["123456789"]
    },
    "whatsapp": {
      "enabled": false
    }
  },
  "tools": {
    "web": {
      "search": {
        "apiKey": "BSA..."
      }
    }
  }
}
```

</details>

## CLI Reference

| Command | Description |
|---------|-------------|
| `nanobot onboard` | Initialize config & workspace |
| `nanobot agent -m "..."` | Chat with the agent |
| `nanobot agent` | Interactive chat mode |
| `nanobot gateway` | Start the gateway |
| `nanobot status` | Show status |
| `nanobot channels login` | Link WhatsApp (scan QR) |
| `nanobot channels status` | Show channel status |
| `nanobot sessions compact <key>` | Manually compact a session |
| `nanobot config compaction` | View/configure compaction settings |
| `nanobot config compaction-model <model>` | Set per-model compaction settings |

<details>
<summary><b>Scheduled Tasks (Cron)</b></summary>

```bash
# Add a job
nanobot cron add --name "daily" --message "Good morning!" --cron "0 9 * * *"
nanobot cron add --name "hourly" --message "Check status" --every 3600

# List jobs
nanobot cron list

# Remove a job
nanobot cron remove <job_id>
```

</details>

## üê≥ Docker

> [!TIP]
> The `-v ~/.nanobot:/root/.nanobot` flag mounts your local config directory into the container, so your config and workspace persist across container restarts.

Build and run nanobot in a container:

```bash
# Build the image
docker build -t nanobot .

# Initialize config (first time only)
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot onboard

# Edit config on host to add API keys
vim ~/.nanobot/config.json

# Run gateway (connects to Telegram/WhatsApp)
docker run -v ~/.nanobot:/root/.nanobot -p 18790:18790 nanobot gateway

# Or run a single command
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot agent -m "Hello!"
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot status
```


## ü§ù Contribute & Roadmap

PRs welcome! The codebase is intentionally small and readable. ü§ó

**Roadmap** ‚Äî Pick an item and [open a PR](https://github.com/eigmax/nanobot/pulls)!

- [x] **Voice Transcription** ‚Äî Support for Groq Whisper (Issue #13)
- [ ] **Multi-modal** ‚Äî See and hear (images, voice, video)
- [x] **Long-term memory** ‚Äî Never forget important context
- [ ] **Better reasoning** ‚Äî Multi-step planning and reflection
- [ ] **More integrations** ‚Äî Discord, Slack, email, calendar
- [ ] **Self-improvement** ‚Äî Learn from feedback and mistakes

### Contributors

<a href="https://github.com/eigmax/nanobot/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=eigmax/nanobot" />
</a>


## ‚≠ê Star History

<div align="center">
  <a href="https://star-history.com/#eigmax/nanobot&Date">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=eigmax/nanobot&type=Date&theme=dark" />
      <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=eigmax/nanobot&type=Date" />
      <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=eigmax/nanobot&type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" />
    </picture>
  </a>
</div>

<p align="center">
  <em> Thanks for visiting ‚ú® nanobot!</em><br><br>
  <img src="https://visitor-badge.laobi.icu/badge?page_id=eigmax.nanobot&style=for-the-badge&color=00d4ff" alt="Views">
</p>


<p align="center">
  <sub>nanobot is for educational, research, and technical exchange purposes only</sub>
</p>
